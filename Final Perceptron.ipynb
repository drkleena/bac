{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import spacy\n",
    "nlp = spacy.blank(\"en\")\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict as dd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from processing_functions import Preprocess as process\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "STOP = stopwords.words('english')\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "\n",
    "CATEGORIES = [\"14-16\", \"24-26\", \"34-36\", \"44-46\",\"?\"]\n",
    "CATEGORIES_INDEX = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read(file):\n",
    "    df = pd.read_csv(\"./COMP30027_2018S1_proj2-data/\"+file+\".csv\",header=None)\n",
    "    return df\n",
    "def categorise_targets(num):\n",
    "    if num <= 16:\n",
    "        return 0\n",
    "    if (num>=24) and (num<=26):\n",
    "        return 1\n",
    "    if (num>=34) and (num<=36):\n",
    "        return 2\n",
    "    if (num>=44) and (num<=46):\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "def tokenise(text):\n",
    "\n",
    "    text = ' '.join(text.split())\n",
    "    text = text.split(\" \")\n",
    "    \n",
    "  \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_output_train_test_split(train, test):\n",
    "    \n",
    "    train_raw = read(train)\n",
    "    test_raw = read(test)\n",
    "    \n",
    "    train_raw = train_raw.loc[:, [0,6,2]]\n",
    "    \n",
    "    train_raw.columns = [\"id\",\"document\", \"age\"]\n",
    "    \n",
    "    \n",
    "    test_raw = test_raw.loc[:, [0,6,2]]\n",
    "    \n",
    "    test_raw.columns = [\"id\",\"document\", \"age\"]\n",
    "    \n",
    "#     test_clean = remove_empty(test_raw)\n",
    "    \n",
    "    #train_raw = train_raw.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_text  = train_raw['document']\n",
    "    test_text =  test_raw['document']\n",
    "    train_target = train_raw['age']\n",
    "    test_target = test_raw['age']\n",
    "    \n",
    "    train_target = train_target.apply(categorise_targets)\n",
    "    test_target = test_target.apply(categorise_targets)\n",
    "    \n",
    "    return ((train_text, train_target),(test_text, test_target),(train_raw, test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = read_and_output_train_test_split(\"train_raw\", \"dev_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_text = data[0][0]\n",
    "train_target = data[0][1]\n",
    "\n",
    "test_text = data[1][0]\n",
    "test_target = data[1][1]\n",
    "\n",
    "\n",
    "training_data = data[2][0]\n",
    "test_data = data[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def create_author_dict(df):\n",
    "        \n",
    "    author_dict = {}\n",
    "    \n",
    "    for index in df.index:\n",
    "        try:\n",
    "            author_dict[df['id'][index]]+=df['document'][index]\n",
    "\n",
    "        except KeyError:\n",
    "            author_dict.update({df['id'][index]:df['document'][index]})\n",
    "            \n",
    "    return author_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def target_to_unique_dict(df):\n",
    "    # unique list of authors and their respective ages in index form (0->4)\n",
    "    train_target_author_dict = {}\n",
    "    for index in df['id'].index:\n",
    "        if (df['id'][index]) not in list(train_target_author_dict.keys()):\n",
    "            train_target_author_dict[df['id'][index]] = df['age'][index]\n",
    "\n",
    "    train_target_author_series = pd.Series(train_target_author_dict)\n",
    "\n",
    "    train_target_author_series=train_target_author_series.apply(categorise_targets)\n",
    "    return train_target_author_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_target_compiled = target_to_unique_dict(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_dict = create_author_dict(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text_compiled = pd.Series(list(author_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    Douglas Rushkoff's Frontline docu...\n",
       "1              I received a short E-mail from the loca...\n",
       "2                  I need more time in the day where i...\n",
       "3               Entry originally posted on 8 August 20...\n",
       "4           BETRAYED   2:19 am birthed the Aries moon ...\n",
       "5                  Well, I decided to start this site ...\n",
       "6                  My possible classes for the Spring/...\n",
       "7                    06.02.00 'Why do all these people...\n",
       "8              Greetings, droogies.  After a tantalisi...\n",
       "9                    After Marissa's 2nd bday, my mom ...\n",
       "10                 New Year's a coming The snow is fal...\n",
       "11                   Well, no new art art persay, but ...\n",
       "12             Buying flat. Getting new kitchen in. Fl...\n",
       "13                     We went to Hagenbeck's Tierpark...\n",
       "14                         Pecking Peggy             O...\n",
       "15                        coffee count: XX    singing ...\n",
       "16         Yep, it's officially official.  I work for ...\n",
       "17                 Like Paul H. I've been looking skep...\n",
       "18                        The very first issue of  Gam...\n",
       "19                 So after a weekend of kids and swim...\n",
       "20                [ This is hey, v4.4 ][ Ending is 'la...\n",
       "21                    urlLink                         ...\n",
       "22                   Thanks Ned for having me over for...\n",
       "23                 Some people move to London for a jo...\n",
       "24                  Listening For Smiles . Read it eve...\n",
       "25             Billy Zane is, without a doubt, in poss...\n",
       "26                  R.I.P  Johnny Cash        &  John ...\n",
       "27                 First written 22. December. 2000   ...\n",
       "28                   I'm in Boston now, at yet another...\n",
       "29                Happy New Year!!    Last night's new...\n",
       "                              ...                        \n",
       "8920              There are several things in existenc...\n",
       "8921              I have been trying so hard to create...\n",
       "8922                 Well I don't really know what to ...\n",
       "8923           Im not spanish but i feel like saying i...\n",
       "8924           Yesterday, at four am, I was on the pho...\n",
       "8925           So many things are changing in our live...\n",
       "8926             This may possibly the most interestin...\n",
       "8927            Tuesday night was spent with my former...\n",
       "8928            Psychologists say all of our earliest ...\n",
       "8929            urlLink    dude check out this tree!!!...\n",
       "8930              I have a dream.  In this dream I've ...\n",
       "8931                     'Good morning! We are pleased...\n",
       "8932           Welcome to the 'Grand Music for Tiny So...\n",
       "8933             BASIC INFORMATION WINDOW  All of char...\n",
       "8934            About Edispuut meetings  An Edispuut m...\n",
       "8935                                                  ...\n",
       "8936               Woohoo, how exciting! My very first...\n",
       "8937                      Last night Robert and I went...\n",
       "8938            urlLink Sports - World record for Mich...\n",
       "8939            ugh, the first post of many, I guess.....\n",
       "8940            Welcome!   As soon as we can, Jon and ...\n",
       "8941        Me, being random and all decided that I ne...\n",
       "8942           After that hard work of finish's Dift's...\n",
       "8943           Britney & Beau's Video Wedding(E! Onlin...\n",
       "8944                 The first post is the first impre...\n",
       "8945                 Hmm, now that I have did all the ...\n",
       "8946                     For some reason, I'm obsessed...\n",
       "8947           Iâ€™m pissed off at this movie and at M. ...\n",
       "8948           This may be a bit of a rush; after all,...\n",
       "8949                 It has been said the most importa...\n",
       "Length: 8950, dtype: object"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn import tree\n",
    "\n",
    "def train(train_text_compiled, train_target_compiled):\n",
    "    \n",
    "    # buliding a pipeline\n",
    "    text_clf = Pipeline([\n",
    "        \n",
    "        ('vectorizer', TfidfVectorizer(stop_words=STOP, max_df=0.50)),\n",
    "        \n",
    "        ('clf', Perceptron(random_state=100, warm_start=True, max_iter=2000))\n",
    "        \n",
    "\n",
    "    ])\n",
    "\n",
    "    text_clf.fit(train_text_compiled, train_target_compiled);\n",
    "    \n",
    "    \n",
    "      # return ((\"Accuracy: \"+ str(100*np.mean(predicted==test_target))+\"%\"), predicted)\n",
    "    return (text_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_clf = train(train_text_compiled, train_target_compiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vectorizer',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs',...\"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'urlLink', 'urlLink', 'urlLink'],\n",
       "          strip_accents=None, sublinear_tf=False,\n",
       "          token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None)),\n",
       " ('clf',\n",
       "  Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "        max_iter=2000, n_iter=None, n_jobs=1, penalty=None, random_state=100,\n",
       "        shuffle=True, tol=None, verbose=0, warm_start=True))]"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_author_dict = create_author_dict(test_data)\n",
    "test_text_compiled = pd.Series(list(test_author_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(test_text_compiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_target_compiled = target_to_unique_dict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62057448229792922"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_target_compiled==predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[471,  45,   2,   0,   0],\n",
       "       [ 57, 438,  25,   4,   0],\n",
       "       [ 11,  59,  19,   0,   0],\n",
       "       [  3,  17,   7,   1,   0],\n",
       "       [111, 203,  16,   8,   0]])"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk.metrics.confusion_matrix(test_target_compiled, predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
